{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1KSvV6XuzwkeANpY672N8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmrWhNVGOl51"
      },
      "outputs": [],
      "source": [
        "import os, logging, pandas\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"/tmp/data\"):\n",
        "\n",
        "  os.makedirs(\"/tmp/data\")"
      ],
      "metadata": {
        "id": "lbSBGPTtOv3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://cloud-training-demos/feat_eng/data/taxi*.csv /tmp/data"
      ],
      "metadata": {
        "id": "PtOl8dvZO-tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/tmp/data\")"
      ],
      "metadata": {
        "id": "ax9qLFeYPD09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pandas.read_table('/tmp/data/taxi-train.csv', sep=',')\n",
        "\n",
        "sample.shape[1]"
      ],
      "metadata": {
        "id": "_QCd2Mj_PGuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.columns.tolist()[:4]"
      ],
      "metadata": {
        "id": "Rul-7HC6PQt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample.columns.tolist()[4:]"
      ],
      "metadata": {
        "id": "snRN-dAHPTMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LabelColumn = sample.columns.tolist()[0]\n",
        "\n",
        "FeatureCols = sample.columns.tolist()[1:]\n",
        "\n",
        "len(FeatureCols)"
      ],
      "metadata": {
        "id": "IoSdsXK_PXBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.data.experimental import make_csv_dataset\n",
        "\n",
        "def FeatureLabel(dataset):\n",
        "  \"\"\"\n",
        "  Feature & Label\n",
        "  \"\"\"\n",
        "  label = dataset.pop(LabelColumn)\n",
        "\n",
        "  return dataset, label\n",
        "\n",
        "def CreateShuffleDataset(pattern, batches, mode='eval'):\n",
        "  \"\"\"\n",
        "  Create Shuffle Dataset\n",
        "\n",
        "  >>> CreateShuffleDataset('taxi-train.csv', 2, 'train')\n",
        "\n",
        "  >>> CreateShuffleDataset('taxi-train.csv', 2)\n",
        "  \"\"\"\n",
        "  dataset = make_csv_dataset(pattern, batches)\n",
        "  dataset = dataset.map(FeatureLabel).cache()\n",
        "  if mode == 'train':\n",
        "    # Shuffle Train Dataset\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "    dataset = dataset.prefetch(1)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "4TBpnukMPyno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from tensorflow import feature_column as fc\n",
        "\n",
        "def BuildModel():\n",
        "  \"\"\"\n",
        "  Functional Model\n",
        "  \"\"\"\n",
        "  inputs = {}; feature_columns = {}\n",
        "  # Input Layer\n",
        "  for colname in FeatureCols:\n",
        "    inputs[colname] = layers.Input(name=colname, shape=(), dtype='float32')\n",
        "  # Set Feature Columns\n",
        "  for colname in FeatureCols:\n",
        "    feature_columns[colname] = fc.numeric_column(colname)\n",
        "  # Hidden Layer\n",
        "  # Dense Features Error to Deprecate, Find Something Similar in Function !\n",
        "  dnn_inputs = layers.DenseFeatures(feature_columns.values())(inputs)\n",
        "  first_layer = layers.Dense(32, activation='relu')(dnn_inputs)\n",
        "  second_layer = layers.Dense(8, activation='relu')(first_layer)\n",
        "  output = layers.Dense(1, activation='linear')(second_layer)\n",
        "  # Create Model\n",
        "  model = models.Model(inputs, output)\n",
        "  # Model Compile\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "CffisFNwRDyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainExamples = len(pandas.read_table('/tmp/data/taxi-train.csv', sep=','))\n",
        "\n",
        "ValidExamples = len(pandas.read_table('/tmp/data/taxi-valid.csv', sep=','))\n",
        "\n",
        "TrainBatchSize = 32"
      ],
      "metadata": {
        "id": "GdRdxP4ASBbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}